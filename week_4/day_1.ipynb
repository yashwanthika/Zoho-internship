{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4\n",
    "# day1: 29 Aug 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Learn about Gradient Descent and its below variants:\n",
    "\n",
    "    Momentum\n",
    "\n",
    "    Nesterov\n",
    "\n",
    "    Adagrad\n",
    "\n",
    "    RMSProp\n",
    "\n",
    "    Adam\n",
    "5. Implement all the above in Numpy\n",
    "6. How does the \"Exponential weighted average\" lecture given in the readings   relate to some of the variants of Gradient Descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.0, 3.0, 7.0, 2.0, 5.0, 4.0])\n",
    "y = np.array([4.0, 9.0, 20.0, 7.0, 15.0, 11.0])\n",
    "\n",
    "\n",
    "def linear_regression(x, m, b):\n",
    "    yhat = x * m + b\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent\n",
    "class GradientDescent:\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 0.001\n",
    "        self.w = 1\n",
    "        self.b = 0\n",
    "\n",
    "    def update_weight(self, x, y):\n",
    "        yhat = self.w * x + self.b\n",
    "        self.w = self.w + self.learning_rate * (-2 * sum(x * (yhat - y)).mean())\n",
    "        self.b = self.b + self.learning_rate * (-2 * sum(yhat - y).mean())\n",
    "\n",
    "    def MSE(self, y, yhat):\n",
    "        return np.square(np.subtract(y, yhat)).mean()\n",
    "\n",
    "    def fit(self, x, y, epochs=200):\n",
    "        history = []\n",
    "        for e in range(epochs):\n",
    "            self.update_weight(x, y)\n",
    "            loss = self.MSE(y, (self.w * x + self.b))\n",
    "            if e % 10 == 0:\n",
    "                print(f\"Epoch: {e}, Loss: {loss}\")\n",
    "                print(f\"weight:{self.w},bias:{self.b}\")\n",
    "            history.append(loss)\n",
    "            if loss <= 1:\n",
    "                print(f\"Epoch: {e}, Loss: {loss}\")\n",
    "                print(f\"weight:{self.w},bias:{self.b}\")\n",
    "                return history\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 39.748544)\n",
      "weight:1.4,bias:0.088\n",
      "Epoch: 9, Loss: 0.8453337832672307)\n",
      "weight:2.67852137518646,bias:0.38249332229004845\n",
      "yhat:[ 3.0610147   8.41805745 19.13214295  5.73953607 13.7751002  11.09657882]\n"
     ]
    }
   ],
   "source": [
    "gd = GradientDescent()\n",
    "gd.fit(x, y)\n",
    "print(f\"yhat:{linear_regression(x,gd.w,gd.b)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum\n",
    "class MomentumGradientDescent:\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 0.01\n",
    "        self.momentum = 0.9\n",
    "        self.w = 0.1\n",
    "        self.b = 0\n",
    "        self.update_w = 0\n",
    "        self.update_b = 0\n",
    "\n",
    "    def update_weight(self, x, y):\n",
    "        yhat = self.w * x + self.b\n",
    "        self.update_w = self.momentum * self.update_w + self.learning_rate * (\n",
    "            -2 * sum(x * (y - yhat)).mean()\n",
    "        )\n",
    "        self.update_b = self.momentum * self.update_b + self.learning_rate * (\n",
    "            -2 * sum(y - yhat).mean()\n",
    "        )\n",
    "\n",
    "    def MSE(self, y, yhat):\n",
    "        return np.square(np.subtract(y, yhat)).mean()\n",
    "\n",
    "    def fit(self, x, y, epochs=200):\n",
    "        history = []\n",
    "        for e in range(epochs):\n",
    "            self.update_weight(x, y)\n",
    "            self.w -= self.update_w\n",
    "            self.b -= self.update_b\n",
    "            loss = self.MSE(y, (self.w * x + self.b))\n",
    "            if e % 10 == 0:\n",
    "                print(f\"Epoch: {e}, Loss: {loss}\")\n",
    "                print(f\"weight:{self.w},bias:{self.b}\")\n",
    "            history.append(loss)\n",
    "            if loss <= 1:\n",
    "                print(f\"Epoch: {e}, Loss: {loss}\")\n",
    "                print(f\"weight:{self.w},bias:{self.b}\")\n",
    "                return history\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 191.13175999999984)\n",
      "weight:5.971999999999999,bias:1.276\n",
      "Epoch: 10, Loss: 41.27352476256328)\n",
      "weight:1.193298498062794,bias:0.90349420802679\n",
      "Epoch: 20, Loss: 15.495612372224036)\n",
      "weight:1.7100754931247293,bias:1.294901243640644\n",
      "Epoch: 25, Loss: 0.4361180426951019)\n",
      "weight:2.5191200581112025,bias:1.372701473355113\n",
      "yhat:[ 3.89182153  8.93006165 19.00654188  6.41094159 13.96830176 11.44918171]\n"
     ]
    }
   ],
   "source": [
    "mgd = MomentumGradientDescent()\n",
    "mgd.fit(x, y)\n",
    "print(f\"yhat:{linear_regression(x,mgd.w,mgd.b)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nestrov\n",
    "class NestrovAcceleratedGradientDescent:\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 0.01\n",
    "        self.momentum = 0.9\n",
    "        self.w = 0.1\n",
    "        self.b = 0\n",
    "        self.update_w = 0\n",
    "        self.update_b = 0\n",
    "\n",
    "    def update_weight(self, x, y):\n",
    "        yhat = self.w * x + self.b\n",
    "        self.w_look_ahead = (\n",
    "            -2 * sum(x * (y - yhat)).mean()\n",
    "        ) - self.momentum * self.update_w\n",
    "        self.b_look_ahead = (-2 * sum(y - yhat).mean()) - self.momentum * self.update_b\n",
    "        yhat_look_ahead = self.w_look_ahead * x + self.b_look_ahead\n",
    "        self.update_w = self.momentum * self.update_w + self.learning_rate * (\n",
    "            -2 * sum(x * (y - yhat_look_ahead)).mean()\n",
    "        )\n",
    "        self.update_b = self.momentum * self.update_b + self.learning_rate * (\n",
    "            -2 * sum(y - yhat_look_ahead).mean()\n",
    "        )\n",
    "\n",
    "    def MSE(self, y, yhat):\n",
    "        return np.square(np.subtract(y, yhat)).mean()\n",
    "\n",
    "    def fit(self, x, y, epochs=200):\n",
    "        history = []\n",
    "        for e in range(epochs):\n",
    "            self.update_weight(x, y)\n",
    "            self.w -= self.update_w\n",
    "            self.b -= self.update_b\n",
    "            loss = self.MSE(y, (self.w * x + self.b))\n",
    "            if e % 10 == 0:\n",
    "                print(f\"Epoch: {e}, Loss: {loss})\")\n",
    "            history.append(loss)\n",
    "            if loss <= 1:\n",
    "                print(f\"Epoch: {e}, Loss: {loss})\")\n",
    "                return history\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 191.13175999999984)\n",
      "weight:5.971999999999999,bias:1.276\n",
      "Epoch: 10, Loss: 41.27352476256328)\n",
      "weight:1.193298498062794,bias:0.90349420802679\n",
      "Epoch: 20, Loss: 15.495612372224036)\n",
      "weight:1.7100754931247293,bias:1.294901243640644\n",
      "Epoch: 25, Loss: 0.4361180426951019)\n",
      "weight:2.5191200581112025,bias:1.372701473355113\n",
      "2.67852137518646 1.372701473355113\n",
      "[ 4.05122285  9.4082656  20.1223511   6.72974422 14.76530835 12.08678697]\n"
     ]
    }
   ],
   "source": [
    "def linear_regression(x, m, b):\n",
    "    yhat = x * m + b\n",
    "    return yhat\n",
    "\n",
    "\n",
    "x = np.array([1.0, 3.0, 7.0, 2.0, 5.0, 4.0])\n",
    "y = np.array([4.0, 9.0, 20.0, 7.0, 15.0, 11.0])\n",
    "mgd = MomentumGradientDescent()\n",
    "mgd.fit(x, y)\n",
    "print(gd.w, mgd.b)\n",
    "print(linear_regression(x, gd.w, mgd.b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('study_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a24480c7c253f489f01188e56c2de50a3ffa81977a4b76b34cdd2b40b0691c29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
