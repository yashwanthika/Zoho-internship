{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4\n",
    "# day3: 31 Aug 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Learn about Gradient Descent and its below variants:\n",
    "\n",
    "    Momentum\n",
    "\n",
    "    Nesterov\n",
    "\n",
    "    Adagrad\n",
    "\n",
    "    RMSProp\n",
    "\n",
    "    Adam\n",
    "5. Implement all the above in Numpy\n",
    "6. How does the \"Exponential weighted average\" lecture given in the readings   relate to some of the variants of Gradient Descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.0, 3.0, 7.0, 2.0, 5.0, 4.0])\n",
    "y = np.array([4.0, 9.0, 20.0, 7.0, 15.0, 11.0])\n",
    "\n",
    "\n",
    "def linear_regression(x, m, b):\n",
    "    yhat = x * m + b\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSProp\n",
    "class RMSProp:\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 0.1\n",
    "        self.w = 9\n",
    "        self.b = 0\n",
    "        self.update_w = 0\n",
    "        self.update_b = 0\n",
    "        self.epsilon = 1e-6\n",
    "        self.beta = 0.9\n",
    "\n",
    "    def update_weight(self, x, y):\n",
    "        yhat = self.w * x + self.b\n",
    "        self.update_w = self.beta * self.update_w + (1 - self.beta) * (\n",
    "            (-2 * sum(x * (y - yhat)).mean()) ** 2\n",
    "        )\n",
    "        self.update_b = self.beta * self.update_b + (1 - self.beta) * (\n",
    "            (-2 * sum(y - yhat).mean()) ** 2\n",
    "        )\n",
    "        self.w -= (self.learning_rate / np.sqrt(self.update_w + self.epsilon)) * (\n",
    "            -2 * sum(x * (y - yhat)).mean()\n",
    "        )\n",
    "        self.b -= (self.learning_rate / np.sqrt(self.update_b + self.epsilon)) * (\n",
    "            -2 * sum(y - yhat).mean()\n",
    "        )\n",
    "\n",
    "    def MSE(self, y, yhat):\n",
    "        return np.square(np.subtract(y, yhat)).mean()\n",
    "\n",
    "    def fit(self, x, y, epochs=2000):\n",
    "        history = []\n",
    "        for e in range(epochs):\n",
    "            self.update_weight(x, y)\n",
    "            loss = self.MSE(y, (self.w * x + self.b))\n",
    "            if e % 100 == 0:\n",
    "                print(f\"Epoch: {e}, Loss: {loss}\")\n",
    "                print(f\"weight:{self.w},bias:{self.b}\")\n",
    "            history.append(loss)\n",
    "            if loss <= 1:\n",
    "                print(f\"Epoch: {e}, Loss: {loss}\")\n",
    "                print(f\"weight:{self.w},bias:{self.b}\")\n",
    "                return history\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 562.7006622555053\n",
      "weight:8.683772233984152,bias:-0.31622776599415175\n",
      "Epoch: 100, Loss: 2.324351041920164\n",
      "weight:3.325713812214073,bias:-1.807915773506083\n",
      "Epoch: 116, Loss: 0.9664660797786159\n",
      "weight:3.0531544913639608,bias:-0.5783922218373122\n",
      "Prediction:\n",
      "3.0531544913639608 -0.5783922218373122\n",
      "yhat: [ 2.47476227  8.58107125 20.79368922  5.52791676 14.68738023 11.63422574]\n"
     ]
    }
   ],
   "source": [
    "rms = RMSProp()\n",
    "history = rms.fit(x, y)\n",
    "print(\"Prediction:\")\n",
    "print(rms.w, rms.b)\n",
    "print(\"yhat:\", linear_regression(x, rms.w, rms.b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam\n",
    "class Adam:\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 0.1\n",
    "        self.w = 9\n",
    "        self.b = 0\n",
    "        self.update_m_w = 0\n",
    "        self.update_m_b = 0\n",
    "        self.update_v_w = 0\n",
    "        self.update_v_b = 0\n",
    "        self.epsilon = 1e-8\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.99\n",
    "\n",
    "    def update_weight(self, x, y, e):\n",
    "        yhat = self.w * x + self.b\n",
    "        self.update_m_w = self.beta1 * self.update_m_w + (1 - self.beta1) * (\n",
    "            -2 * sum(x * (y - yhat)).mean()\n",
    "        )\n",
    "        self.update_m_b = self.beta1 * self.update_m_b + (1 - self.beta1) * (\n",
    "            -2 * sum(y - yhat).mean()\n",
    "        )\n",
    "        self.update_v_w = self.beta2 * self.update_v_w + (1 - self.beta2) * (\n",
    "            (-2 * sum(x * (y - yhat)).mean()) ** 2\n",
    "        )\n",
    "        self.update_v_b = self.beta2 * self.update_v_b + (1 - self.beta2) * (\n",
    "            (-2 * sum(y - yhat).mean()) ** 2\n",
    "        )\n",
    "        self.update_m_w = self.update_m_w / (1 - self.beta1**e + 1)\n",
    "        self.update_m_b = self.update_m_b / (1 - self.beta1**e + 1)\n",
    "        self.update_v_w = self.update_v_w / (1 - self.beta2**e + 1)\n",
    "        self.update_v_b = self.update_v_b / (1 - self.beta2**e + 1)\n",
    "        self.w -= (self.learning_rate / np.sqrt(self.update_v_w + self.epsilon)) * (\n",
    "            self.update_m_w\n",
    "        )\n",
    "        self.b -= (self.learning_rate / np.sqrt(self.update_v_b + self.epsilon)) * (\n",
    "            self.update_m_b\n",
    "        )\n",
    "\n",
    "    def MSE(self, y, yhat):\n",
    "        return np.square(np.subtract(y, yhat)).mean()\n",
    "\n",
    "    def fit(self, x, y, epochs=2000):\n",
    "        history = []\n",
    "        for e in range(epochs):\n",
    "            self.update_weight(x, y, e)\n",
    "            loss = self.MSE(y, (self.w * x + self.b))\n",
    "            if e % 100 == 0:\n",
    "                print(f\"Epoch: {e}, Loss: {loss}\")\n",
    "                print(f\"weight:{self.w},bias:{self.b}\")\n",
    "            history.append(loss)\n",
    "            if loss <= 1:\n",
    "                print(f\"Epoch: {e}, Loss: {loss}\")\n",
    "                print(f\"weight:{self.w},bias:{self.b}\")\n",
    "                return history\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 615.4566666667038\n",
      "weight:8.90000000000003,bias:-0.09999999999928254\n",
      "Epoch: 100, Loss: 5.544956832672793\n",
      "weight:3.6919044593921315,bias:-3.619330884227773\n",
      "Epoch: 140, Loss: 0.9998795863272743\n",
      "weight:3.049258941689907,bias:-0.6192726745819843\n",
      "Prediction:\n",
      "3.049258941689907 -0.6192726745819843\n",
      "yhat: [ 2.42998627  8.52850415 20.72553992  5.47924521 14.62702203 11.57776309]\n"
     ]
    }
   ],
   "source": [
    "adam = Adam()\n",
    "history = adam.fit(x, y)\n",
    "print(\"Prediction:\")\n",
    "print(adam.w, adam.b)\n",
    "print(\"yhat:\", linear_regression(x, adam.w, adam.b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. How does the \"Exponential weighted average\" lecture given in the readings   relate to some of the variants of Gradient Descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Weight updates are guided by the previous gradients.The most recent gradient provide more information so the older the gradient the lesser the weight should be given thus exponential weightd average is used "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('study_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a24480c7c253f489f01188e56c2de50a3ffa81977a4b76b34cdd2b40b0691c29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
